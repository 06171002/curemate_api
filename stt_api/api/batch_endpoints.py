import os
import uuid
import json
from fastapi import (
    APIRouter,
    UploadFile,
    File,
    Form,
    HTTPException,
    Request,
    Query
)
from typing import Optional
from sse_starlette.sse import EventSourceResponse
from stt_api.services.storage import job_manager, JobType, JobStatus
from stt_api.services import tasks
from stt_api.core.config import settings
from stt_api.core.logging_config import get_logger

logger = get_logger(__name__)


router = APIRouter()


@router.post("/api/v1/conversation/request", status_code=202)
async def create_conversation_request(
        file: UploadFile = File(...),
        cure_seq: Optional[int] = Form(None, description="ì¹˜ë£Œ ID"),
        cust_seq: Optional[int] = Form(None, description="ë³´í˜¸ì ID"),
        patient_seq: Optional[int] = Form(None, description="í™˜ì ID"),
        mode: Optional[str] = Form(None, description="google ë˜ëŠ” None")
):
    """
    ìŒì„± íŒŒì¼ ì—…ë¡œë“œ ë° STT ì‘ì—… ìƒì„±

    Request Body (multipart/form-data):
        - file: ìŒì„± íŒŒì¼ (mp3, wav, m4a)
        - cure_seq: íì–´ë£¸ ê³ ìœ ë²ˆí˜¸
        - cust_seq: ê³ ê° ê³ ìœ ë²ˆí˜¸
    """
    job_id = str(uuid.uuid4())

    # 1. íŒŒì¼ ì €ì¥
    try:
        file_ext = file.filename.split(".")[-1]
        temp_file_path = os.path.join(settings.TEMP_AUDIO_DIR, f"{job_id}.{file_ext}")
        contents = await file.read()
        with open(temp_file_path, "wb") as f:
            f.write(contents)
    except Exception as e:
        logger.error("íŒŒì¼ ì €ì¥ ì‹¤íŒ¨", error_messag=e)
        raise HTTPException(
            status_code=500,
            detail=f"íŒŒì¼ì„ ì„ì‹œ ì €ì¥í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}"
        )

    # 2. DBì— BATCH ì‘ì—… ìƒì„± (ìš°ì„ ìˆœìœ„ 1)
    metadata = {
        "filename": file.filename,
        "file_size": len(contents),
        "file_path": temp_file_path,
        # ğŸ‘‡ ì—¬ê¸°ì— ë„ë©”ì¸ ì¢…ì† ë°ì´í„°ë¥¼ ë„£ìŠµë‹ˆë‹¤.
        "cure_seq": cure_seq,
        "cust_seq": cust_seq,
        "patient_seq": patient_seq,
        "mode": mode,
    }

    # 3. DBì— ì‘ì—… ìƒì„± (âœ… cure_seq, cust_seq ë³„ë„ ì „ë‹¬)
    try:
        success = await job_manager.create_job(
            job_id, JobType.BATCH, metadata=metadata
        )

        if not success:
            if os.path.exists(temp_file_path):
                os.remove(temp_file_path)
            raise HTTPException(status_code=500, detail="ì‘ì—… ìƒì„± ì‹¤íŒ¨")

    except Exception as e:
        if os.path.exists(temp_file_path):
            os.remove(temp_file_path)
        raise HTTPException(status_code=500, detail=f"ì‘ì—… ìƒì„± ì‹¤íŒ¨: {str(e)}")

    # 3. Celery Task ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì˜ˆì•½
    try:
        tasks.run_stt_and_summary_pipeline.delay(job_id, temp_file_path)
        logger.info("ì‘ì—… ìƒì„± ì™„ë£Œ", job_id=job_id)
    except Exception as e:
        error_msg = f"Celery ì‘ì—… ì˜ˆì•½ ì‹¤íŒ¨: {str(e)}"
        logger.error("Celery ì‘ì—… ì˜ˆì•½ ì‹¤íŒ¨", error_msg=e)

        # âœ… JobManagerë¡œ ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸ (await ì¶”ê°€)
        await job_manager.update_status(job_id, JobStatus.COMPLETED, error_message=error_msg)
        await job_manager.log_error(job_id, "celery_task", error_msg)

        raise HTTPException(status_code=500, detail=error_msg)

    return {
        "job_id": job_id,
        "job_type": "BATCH",
        "status": "pending",
        "message": "ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ìš”ì²­ë˜ì—ˆìŠµë‹ˆë‹¤."
    }


@router.get("/api/v1/conversation/result/{job_id}")
async def get_conversation_result(job_id: str):  # âœ… async defë¡œ ë³€ê²½
    # âœ… JobManagerë¡œ ì¡°íšŒ (DB â†’ Redis ìë™ í´ë°±) - await ì¶”ê°€
    job = await job_manager.get_job(job_id)

    if not job:
        raise HTTPException(status_code=404, detail="Job IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return job


@router.get("/api/v1/conversation/stream-events/{job_id}")
async def stream_events(job_id: str, request: Request):
    """
    âœ… ê°œì„ ëœ SSE ìŠ¤íŠ¸ë¦¬ë°:
    1. ì—°ê²° ì‹œ ì´ë¯¸ ì²˜ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë¨¼ì € ì „ì†¡
    2. ì´í›„ ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ êµ¬ë…
    """
    # 1. Job ì¡´ì¬ í™•ì¸ - âœ… await ì¶”ê°€
    job = await job_manager.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="Job IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # âœ… í˜„ì¬ ì‘ì—… ìƒíƒœ ë¯¸ë¦¬ í™•ë³´
    current_job_status = job.get("status", "PENDING")

    async def event_generator():
        try:
            # âœ… STEP 1: ê³¼ê±° ì„¸ê·¸ë¨¼íŠ¸ ì „ì†¡ (DBì—ì„œ ì¡°íšŒ) - await ì¶”ê°€
            past_segments = await job_manager.get_segments(job_id)

            logger.info(
                "[SSE] ê³¼ê±° ì„¸ê·¸ë¨¼íŠ¸ ì „ì†¡ ì‹œì‘",
                job_id=job_id,
                count=len(past_segments)
            )

            for segment in past_segments:
                if await request.is_disconnected():
                    logger.info("[SSE] í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠê¹€ (ê³¼ê±° ë°ì´í„° ì „ì†¡ ì¤‘)")
                    return

                yield {
                    "event": "transcript_segment",
                    "data": json.dumps({
                        "type": "transcript_segment",
                        "text": segment["segment_text"],
                        "segment_number": segment.get("segment_number", 0),
                        "is_historical": True,  # âœ… ê³¼ê±° ë°ì´í„° í‘œì‹œ
                        "status": current_job_status
                    })
                }

            # âœ… STEP 2: í˜„ì¬ ìƒíƒœ í™•ì¸ (ì´ë¯¸ ì™„ë£Œëœ ê²½ìš° final_summary ì „ì†¡)
            current_status = job.get("status", "").upper()

            if current_status == "COMPLETED":
                logger.info("[SSE] ì‘ì—…ì´ ì´ë¯¸ ì™„ë£Œë¨, final_summary ì „ì†¡")

                yield {
                    "event": "final_summary",
                    "data": json.dumps({
                        "type": "final_summary",
                        "summary": job.get("structured_summary", {}),
                        "segment_count": len(past_segments),
                        "is_historical": True,
                        "status": "COMPLETED"
                    })
                }
                return  # ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ

            # âœ… STEP 3: ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ êµ¬ë… (ì§„í–‰ ì¤‘ì¸ ê²½ìš°)
            logger.info("[SSE] ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ êµ¬ë… ì‹œì‘", job_id=job_id)

            async for message_data in job_manager.subscribe_events(job_id):
                if await request.is_disconnected():
                    logger.info("[SSE] í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠê¹€ (ì‹¤ì‹œê°„ êµ¬ë… ì¤‘)")
                    break

                event_type = message_data.get("type", "message")
                data_json = json.dumps(message_data)

                yield {
                    "event": event_type,
                    "data": data_json
                }

                # ìµœì¢… ìš”ì•½ ìˆ˜ì‹  ì‹œ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
                if event_type == "final_summary":
                    logger.info("[SSE] ìµœì¢… ìš”ì•½ ì „ì†¡ ì™„ë£Œ, ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ")
                    break

        except Exception as e:
            error_msg = f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {str(e)}"
            logger.error("ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜", error_msg=e)

            # âœ… JobManagerë¡œ ì—ëŸ¬ ë¡œê¹… (await ì¶”ê°€)
            await job_manager.log_error(job_id, "sse_stream", error_msg)

            yield {
                "event": "error",
                "data": json.dumps({"message": error_msg})
            }

    return EventSourceResponse(event_generator())


@router.get("/api/v1/conversation/errors/{job_id}")
async def get_job_errors(job_id: str):  # âœ… async defë¡œ ë³€ê²½
    """
    íŠ¹ì • ì‘ì—…ì˜ ì—ëŸ¬ ë¡œê·¸ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    # âœ… JobManagerë¡œ ì—ëŸ¬ ë¡œê·¸ ì¡°íšŒ (await ì¶”ê°€)
    errors = await job_manager.get_errors(job_id)

    if not errors:
        # Job ìì²´ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (await ì¶”ê°€)
        job_exists = await job_manager.get_job(job_id)
        if not job_exists:
            raise HTTPException(status_code=404, detail="Job IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        return {
            "job_id": job_id,
            "errors": [],
            "message": "ì—ëŸ¬ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤."
        }

    return {
        "job_id": job_id,
        "errors": errors,
        "error_count": len(errors)
    }