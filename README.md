# STT/Summary API

ì‹¤ì‹œê°„ STT(Speech-to-Text) ë° ìš”ì•½ API ì„œë²„ì…ë‹ˆë‹¤.

ì´ í”„ë¡œì íŠ¸ëŠ” `FastAPI`, `Celery`, `Redis`, `faster-whisper`ë¥¼ Docker Composeë¡œ ì‹¤í–‰í•˜ê³ , `Ollama`ëŠ” ë¡œì»¬ í˜¸ìŠ¤íŠ¸(Host) PCì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.

---

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### 1. ì‚¬ì „ ì¤€ë¹„ (ì´ 3ê°€ì§€)

1.  **Docker Desktop**ì„ ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.
2.  **Ollama**ë¥¼ **í˜¸ìŠ¤íŠ¸ PC(Windows/Mac)ì— ì§ì ‘ ì„¤ì¹˜**í•´ì•¼ í•©ë‹ˆë‹¤.
3.  Ollamaì—ì„œ ì‚¬ìš©í•  ëª¨ë¸(`gemma3`)ì„ ë¯¸ë¦¬ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤.
    ```bash
    ollama pull gemma3
    ```

### 2. í”„ë¡œì íŠ¸ í´ë¡ 

### 3. ì‹¤í–‰

1.  **[í„°ë¯¸ë„ 1]** ë¡œì»¬ PC(Windows)ì—ì„œ `Ollama` ì„œë²„ë¥¼ **0.0.0.0 í˜¸ìŠ¤íŠ¸**ë¡œ ì‹¤í–‰ (`$env:OLLAMA_HOST="0.0.0.0"`, `ollama serve`)í•˜ê³  ë°©í™”ë²½ì„ í—ˆìš©í•©ë‹ˆë‹¤.
2.  **[í„°ë¯¸ë„ 2]** `docker-compose up -d --build`ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

----------------------------

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

<details>
<summary>ğŸ‘‰ ë””ë ‰í† ë¦¬ êµ¬ì¡° í¼ì¹˜ê¸°/ì ‘ê¸°</summary>
```bash
stt_api/
â”œâ”€â”€ __init__.py                    # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”œâ”€â”€ main.py                        # FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
â”‚
â”œâ”€â”€ core/                          # ğŸ”§ í•µì‹¬ ì„¤ì • ë° ì¸í”„ë¼
â”‚   â”œâ”€â”€ config.py                  # í™˜ê²½ ì„¤ì • (Settings, Constants)
â”‚   â”œâ”€â”€ celery_config.py           # Celery ì‘ì—… í ì„¤ì •
â”‚   â”œâ”€â”€ logging_config.py          # êµ¬ì¡°í™”ëœ ë¡œê¹… (JSON/Color)
â”‚   â””â”€â”€ exceptions.py              # ì»¤ìŠ¤í…€ ì˜ˆì™¸ ì •ì˜
â”‚
â”œâ”€â”€ domain/                        # ğŸ“¦ ë„ë©”ì¸ ëª¨ë¸
â”‚   â””â”€â”€ streaming_job.py           # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ ì‘ì—… ëª¨ë¸ (VAD ë“±)
â”‚
â”œâ”€â”€ services/                      # ğŸ› ï¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì„œë¹„ìŠ¤
â”‚   â”œâ”€â”€ stt/                       # ğŸ¤ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜
â”‚   â”‚   â”œâ”€â”€ whisper_service.py     # Whisper ëª¨ë¸ í•¸ë“¤ëŸ¬
â”‚   â”‚   â””â”€â”€ vad_processor.py       # ìŒì„± í™œë™ ê°ì§€ (VAD)
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/                       # ğŸ¤– LLM ìš”ì•½ ì„œë¹„ìŠ¤
â”‚   â”‚   â”œâ”€â”€ ollama_service.py      # Ollama (Local) êµ¬í˜„ì²´
â”‚   â”‚   â””â”€â”€ lm_service.py          # LM Studio êµ¬í˜„ì²´
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                   # ğŸ’¾ ë°ì´í„° ì €ì¥ì†Œ
â”‚   â”‚   â”œâ”€â”€ job_manager.py         # ì‘ì—… ìƒëª…ì£¼ê¸° ê´€ë¦¬ (DB+Redis)
â”‚   â”‚   â””â”€â”€ cache_service.py       # Redis ìºì‹œ & Pub/Sub
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/                  # ğŸ”„ ì›Œí¬í”Œë¡œìš° íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ batch_pipeline.py      # ë°°ì¹˜ ì²˜ë¦¬ (íŒŒì¼ ì—…ë¡œë“œ)
â”‚   â”‚   â””â”€â”€ stream_pipeline.py     # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (WebSocket)
â”‚   â”‚
â”‚   â””â”€â”€ tasks.py                   # âš™ï¸ Celery ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
â”‚
â””â”€â”€ api/                           # ğŸŒ API ì—”ë“œí¬ì¸íŠ¸
    â”œâ”€â”€ batch_endpoints.py         # ë°°ì¹˜ ì‘ì—… API
    â””â”€â”€ stream_endpoints.py        # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ API
</details>

---------------------
## ğŸ’¾ íŒŒì¼ í›„ì²˜ë¦¬ (SSE) ì•„í‚¤í…ì²˜ íë¦„

`POST /api/v1/conversation/request` (íŒŒì¼ ì—…ë¡œë“œ)ì™€ `GET /api/v1/conversation/stream-events/{job_id}` (SSE ìŠ¤íŠ¸ë¦¼) ìš”ì²­ ì‹œì˜ ìƒì„¸ íë¦„ì…ë‹ˆë‹¤.

sequenceDiagram
    participant C as Client (App)
    participant API as API Server
    participant R as Redis (Pub/Sub)
    participant W as Celery Worker
    participant L as LLM (Ollama)

    Note over C, API: 1ë‹¨ê³„: ì‘ì—… ìš”ì²­
    C->>API: POST /request (Audio File)
    API->>R: Create Job (Pending)
    API->>W: Task Queueing (Celery)
    API-->>C: Return {job_id}

    Note over C, API: 2ë‹¨ê³„: ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ êµ¬ë…
    C->>API: GET /stream-events/{job_id}
    API->>R: Subscribe (Pub/Sub)

    Note over W, L: 3ë‹¨ê³„: ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬
    W->>W: STT Processing (Whisper)
    loop Every Segment
        W->>R: Publish "transcript_segment"
        R-->>API: Event Message
        API-->>C: SSE Send (Segment Text)
    end

    W->>L: Request Summary (Full Text)
    L-->>W: Return JSON Summary
    W->>R: Publish "final_summary"
    R-->>API: Event Message
    API-->>C: SSE Send (Final Summary)




---------------------


## ğŸš€ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° (WebSocket) ì•„í‚¤í…ì²˜ íë¦„

`test_real_audio_stream.py` ì‹¤í–‰ ì‹œ, í´ë¼ì´ì–¸íŠ¸-ì„œë²„-ì„œë¹„ìŠ¤ ê°„ì˜ ìƒì„¸í•œ ìƒí˜¸ì‘ìš© íë¦„ì…ë‹ˆë‹¤.

| ğŸ¤– í´ë¼ì´ì–¸íŠ¸ (`test_real_audio_stream.py`) | ğŸ–¥ï¸ API ì„œë²„ (FastAPI / `api/stream_endpoints.py`) | ğŸ§  ì„œë¹„ìŠ¤ (STT/VAD/LLM) |
| :--- | :--- | :--- |
| **(1ë‹¨ê³„: Job ìƒì„±)** | | |
| 1. `requests.post(".../api/v1/stream/create")` (HTTP ìš”ì²­) | 2. `create_stream_job()` í˜¸ì¶œ. <br/> `job = StreamingJob()` (`domain`) <br/> `active_jobs[job_id] = job` (`core.config`) <br/> `cache_service.create_job()` (Redis) | 3. `(VADProcessor)`ê°€ `StreamingJob` ë‚´ë¶€ì— ìƒì„±ë¨ |
| 4. `{"job_id": ...}` ì‘ë‹µ ìˆ˜ì‹  | 5. `job_id` ë°˜í™˜ | |
| **(2ë‹¨ê³„: WebSocket ì—°ê²°)** | | |
| 6. `ws.run_forever()`ë¡œ `ws://.../{job_id}` ì—°ê²° (ë©”ì¸ ìŠ¤ë ˆë“œ ëŒ€ê¸°) | 7. `conversation_stream()` í•¸ë“¤ëŸ¬ ì‹œì‘. <br/> `job = active_jobs.get(job_id)` <br/> `await websocket.accept()` (ì—°ê²° ìˆ˜ë½). <br/> â¡ï¸ `(WS) "connection_success" ì „ì†¡` | |
| 8. `on_open()` í•¸ë“¤ëŸ¬ ì‹¤í–‰: <br/> `send_audio_stream()` í•¨ìˆ˜ë¥¼ **ìƒˆ ìŠ¤ë ˆë“œ**ë¡œ ì‹œì‘. | | |
| 9. `on_message()` í•¸ë“¤ëŸ¬ ì‹¤í–‰: <br/> "connection_success" ë©”ì‹œì§€ ìˆ˜ì‹  ë° ì¶œë ¥. | | |
| **(3ë‹¨ê³„: STT/VAD ì²˜ë¦¬ ë£¨í”„)** | | |
| 10. **(ì˜¤ë””ì˜¤ ìŠ¤ë ˆë“œ)** <br/> `AudioSegment.from_file(MP3)` <br/> `audio.set_frame_rate(16000)...` (PCM ë³€í™˜) <br/> `for chunk in ...:` ë£¨í”„ ì‹œì‘ <br/> â¡ï¸ `(WS) 960 ë°”ì´íŠ¸ ì²­í¬ ì „ì†¡` <br/> `time.sleep(0.030)` | 11. **(ì„œë²„ ë¹„ë™ê¸° ë£¨í”„)** <br/> `await websocket.receive_bytes()` (ì²­í¬ ìˆ˜ì‹ ) <br/> `job.process_audio_chunk(chunk)` í˜¸ì¶œ | 12. **(`utils/vad.py`)** <br/> `VADProcessor.process_chunk()`ê°€ `speech_buffer`ì— ì²­í¬ ì €ì¥ |
| ... (ì²­í¬ ê³„ì† ì „ì†¡) | ... (ì²­í¬ ìˆ˜ì‹  â¡ï¸ VAD ì „ë‹¬ ë°˜ë³µ) | ... (ìŒì„± ì²­í¬ `buffer`ì— ëˆ„ì ) |
| | 13. **ì¹¨ë¬µ ê°ì§€!** (`max_silence_frames` ë„ë‹¬) | 14. (`utils/vad.py`) `segment_bytes` (ì˜¤ë””ì˜¤ ë©ì–´ë¦¬) ë°˜í™˜ |
| | 15. `if segment_bytes:` True! <br/> `await asyncio.to_thread(stt_service...)` (STTë¥¼ **ë³„ë„ ìŠ¤ë ˆë“œ**ì—ì„œ ì‹¤í–‰) | 16. **(`services/stt_service.py`)** <br/> `transcribe_segment_from_bytes()` (ë™ê¸°) ì‹¤í–‰ <br/> (STT ì²˜ë¦¬...) <br/> `segment_text` ë°˜í™˜ |
| | 17. `segment_text` ìˆ˜ì‹  (`job` ê°ì²´ì— ì €ì¥) <br/> â¡ï¸ `(WS) "transcript_segment" ì „ì†¡` | |
| 18. `on_message()` í•¸ë“¤ëŸ¬ ì‹¤í–‰: <br/> `{"type":"transcript_segment", ...}` ìˆ˜ì‹  ë° ì¶œë ¥ | (ë£¨í”„ê°€ 11ë²ˆìœ¼ë¡œ ëŒì•„ê°€ ë‹¤ìŒ ì²­í¬ ëŒ€ê¸°) | (ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ ëŒ€ê¸°) |
| **(4ë‹¨ê³„: ì—°ê²° ì¢…ë£Œ)** | | |
| 19. **(ì˜¤ë””ì˜¤ ìŠ¤ë ˆë“œ)** <br/> `for` ë£¨í”„ ì¢…ë£Œ. <br/> `time.sleep(10)` (10ì´ˆ ëŒ€ê¸°) <br/> â¡ï¸ `ws.close()` (ì—°ê²° ì¢…ë£Œ ìš”ì²­) | 20. **(ì„œë²„ ë¹„ë™ê¸° ë£¨í”„)** <br/> `await websocket.receive_bytes()`ì—ì„œ `WebSocketDisconnect` ì˜ˆì™¸ ë°œìƒ. <br/> `except WebSocketDisconnect:` ë¸”ë¡ ì§„ì…. | |
| | 21. `final_transcript = job.get_full_transcript()` (ëˆ„ì ëœ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°) <br/> `await ollama_service.get_summary(...)` í˜¸ì¶œ | 22. **(`services/ollama_service.py`)** <br/> `get_summary()` ì‹¤í–‰ (ìš”ì•½ ìš”ì²­) |
| | 23. `summary_dict` ë°›ìŒ. <br/> `cache_service.update_job(...)` (Redis "completed" ì €ì¥). <br/> â¡ï¸ `(WS) "final_summary" ì „ì†¡ ì‹œë„`. <br/> `finally:` ë¸”ë¡ ì§„ì… (`del active_jobs[job_id]`). | |
| 24. **(ë©”ì¸ ìŠ¤ë ˆë“œ)** <br/> `on_close()` í•¸ë“¤ëŸ¬ ì‹¤í–‰. <br/> `ws.run_forever()` ì¢…ë£Œ. <br/> **í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ.** | | |